# Challenge 0
# Ordinary least squares (OLS) regression "by hand"

## 1. Generate toy predictor (X) and response (Y) variables
```{r}
X = c(2, 4, 8, 12, 18, 20)
Y = c(1, 3, 5, 9, 19, 21)
```

## 2. Calculate means of X and Y

```{r}
(x_mean = mean(X))
(y_mean = mean(Y))
```

## 3. Calculate error for each observation
```{r}
(x_err = X - x_mean)
(y_err = Y - y_mean)
```

## 4. Plot the data
```{r}
plot(x = X, y = Y, main = "OLS")
```

## 5. Estimate B1 coefficient (slope)

````{r}
B1 = sum(x_err * y_err) / sum(x_err ^2)
B1
```

## 6. Estimate B0 coefficient (intercept)

```{r}
B0 = y_mean - (B1 * x_mean)
B0
```

## 7. Plot the abline

```{r}
abline(B0, B1, col = "green", lwd = 4)
```

## 8. Generate predicted values by plugging in our X values to the equation: 

```{r}
Y_hat = B0 + B1 * X
Y_hat
```

## 9. Calculate root mean sqaure error (RMSE) for our predictions. 

First, calculatte the error for each observation by subracting it from the predicted value:
```{r}
y_obs_err = Y_hat - Y
y_obs_err
```

## 10. Then, calculate the square of each of these errors:
```{r}
y_err_sq = y_obs_err ^ 2
y_err_sq
```

## 11. Sum these values
```{r}
sum_squared_err = sum(y_err_sq)
sum_squared_err
```

## 12. Divide by n and take square root to produce the RMSE:

```{r}
RMSE = sqrt(sum_squared_err / length(Y))
RMSE
```

## 13. Sanity check

```{r}
RMSE == sqrt(sum(y_err_sq) / length(Y))

## double sanity check - fit the model using the lm function in R:
lm_toy = lm(Y ~ X)
lm_toy
B1
B0
summary(lm_toy)

## is our B1 the same as the slope generated by "lm" in R?
round(B1, digits = 5) == round(lm_toy$coefficients[2], digits = 5)

## is our B0 the same as the intercept generated by "lm" in R?
round(B0, digits = 5) == round(lm_toy$coefficients[1], digits = 5)
```